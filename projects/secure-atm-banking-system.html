<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Secure ATM Banking System</title>
  <link rel="stylesheet" href="/css/secure-atm-banking-system.css">
</head>
<body>
  <!-- Dark Mode Toggle Button + Ripple -->
  <button id="darkModeToggle">
    <span id="modeIcon">‚òÄÔ∏è</span>
  </button>
  <div id="ripple"></div>

<!-- Ambient Sound -->
<audio id="ambientAudio" loop preload="auto">
  <source src="/sounds/music/ambient.mp3" type="audio/mp3">
</audio>

<!-- Audio Controls -->
<div class="audio-controls">
  <button id="audioToggle" title="Toggle Sound">üîà</button>
  <div class="slider-wrapper">
    <input type="range" id="volumeSlider" min="0" max="100" value="5">
  </div>
</div>

<!-- Mouse Click Sound -->
<audio id="clickSound" src="/sounds/sfx/mouse_click.mp3" preload="auto"></audio>




  <div id="progress-bar"></div>

  <!-- Hero Section -->
  <section class="hero">
    <canvas id="heroParticles"></canvas>
    <div class="hero-content">
      <h1 class="hero-title">Secure ATM Banking System</h1>
      <p class="hero-subtitle">Java ‚Ä¢ JavaFX Interface ‚Ä¢ Secure Authentication ‚Ä¢ Encrypted Transactions</p>
    </div>
  </section>  
  

  <!-- Scroll Sections -->
  <section class="project-section left">
    <div class="text">
      <h2>Project Overview</h2>
      <p>Our project, <strong>Anomaly Detection in Augmented Reality Environments</strong>, explores the intersection of 
        <strong>machine learning</strong> and <strong>synthetic data generation</strong>. 
        We developed a <strong>real-time anomaly detection system</strong> capable of identifying irregularities in 
        physical environments through <strong>augmented reality</strong> interfaces.
        By combining <strong>Unity3D</strong>'s powerful simulation tools with <strong>TensorFlow</strong>'s efficient modeling capabilities, 
        we demonstrate how <strong>lightweight deep learning models</strong> trained on <strong>synthetic datasets</strong> can be deployed for 
        real-world anomaly detection across industries like <strong>manufacturing</strong>, <strong>logistics</strong>, and 
        <strong>quality control</strong>.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/AnomalyDetection_Dark.png" alt="Description">
    </div>
  </section>
  
  <section class="project-section right">
    <div class="text">
      <h2>Dataset Generation in Unity 3D</h2>
      <p>
        To build a robust anomaly detection model, we first created a fully synthetic dataset using <strong>Unity3D</strong>. 
        Leveraging Unity‚Äôs <strong>Perception package</strong>, we generated thousands of labeled images across a wide range of scenarios.
        We introduced <strong>randomized object placements</strong>, <strong>dynamic lighting conditions</strong>, 
        <strong>different surface textures</strong>, and <strong>background variations</strong> to simulate diverse real-world environments.
        By automating the dataset generation process, we avoided the time-consuming effort of manual data collection and ensured that our model 
        would be trained on a <strong>highly diverse and scalable synthetic dataset</strong>, greatly improving its ability to generalize to unseen environments.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/QuizBot_Light.png
      " alt="Description">
    </div>
  </section>

  <section class="project-section left">
    <div class="text">
      <h2>TensorFlow Training Model</h2>
      <p>
        For our anomaly detection pipeline, we designed a hybrid model architecture that combines a <strong>lightweight EfficientNetB0</strong> feature extractor with a <strong>custom-trained autoencoder</strong>.
        The <strong>EfficientNetB0 backbone</strong> allowed us to maintain high-quality feature representations while keeping the model size optimized for real-time performance.
        We chose <strong>TensorFlow</strong> due to its mature ecosystem, deployment flexibility, and excellent support for <strong>real-time inference</strong> scenarios.
        By integrating a <strong>feature extraction layer</strong> before the autoencoder, we ensured that the model could focus on learning meaningful patterns in the environment, 
        resulting in significantly faster convergence during training and improved generalization to unseen environments.
        This strategic combination allowed us to achieve robust anomaly detection capabilities without relying on excessively large or complex architectures.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/AnomalyDetection_Dark.png" alt="Description">
    </div>
  </section>
  
  <section class="project-section right">
    <div class="text">
      <h2>How We Trained the Model</h2>
      <p>
        Our training strategy was carefully designed to maximize the model's ability to recognize anomalies without relying on labeled defect data. 
        We trained exclusively on <strong>normal samples</strong>, allowing the <strong>autoencoder</strong> to learn a compressed latent representation of expected environments.
        Instead of using traditional loss functions like <strong>Mean Squared Error (MSE)</strong>, we implemented <strong>Structural Similarity Index (SSIM) loss</strong>,
        which prioritizes the preservation of structural details and visual consistency, leading to more reliable anomaly detection.
        To further improve model robustness, we employed extensive <strong>data augmentation</strong> techniques, including <strong>random rotations</strong>, 
        <strong>noise injection</strong>, <strong>brightness shifts</strong>, and <strong>geometric transformations</strong>.
        These augmentations simulated real-world variability and made the model significantly more resilient to changes in lighting, perspective, and scene composition.
        This methodology enabled our model to achieve high precision in identifying subtle deviations without ever seeing defective examples during training.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/QuizBot_Light.png
      " alt="Description">
    </div>
  </section>

  <section class="project-section left">
    <div class="text">
      <h2>User Interface Design</h2>
      <p>
        To deliver real-time anomaly feedback in an intuitive and user-friendly way, we developed a custom interface using <strong>OpenCV</strong> in <strong>Python</strong>. 
        The interface captures a live camera feed and overlays an <strong>anomaly heatmap</strong> generated by the model, highlighting deviations directly on screen.
        Our priority was to ensure <strong>minimal latency</strong> between camera input and model output, making the system feel immediate and responsive.
        We also implemented a <strong>dynamic thresholding system</strong> to control sensitivity, allowing users to fine-tune the detection based on environmental noise.
        The UI was intentionally designed with <strong>simplicity</strong> and <strong>performance</strong> in mind, avoiding unnecessary complexity while maintaining a smooth, real-time experience even on mid-range hardware.
        This user-centric approach made the system not only functional for technical users, but also accessible to non-experts needing fast, visual anomaly insights.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/AnomalyDetection_Dark.png" alt="Description">
    </div>
  </section>
  
  <section class="project-section right">
    <div class="text">
      <h2>Live Results</h2>
      <p>
        Live testing demonstrated the system's ability to detect anomalies reliably across both <strong>synthetic</strong> and <strong>real-world environments</strong>.
        The model consistently identified <strong>unexpected objects</strong>, <strong>lighting changes</strong>, and <strong>scene deviations</strong> that differed from its learned normal patterns.
        We observed detection precision rates exceeding <strong>90%</strong> on synthetic test scenes, and similarly strong performance in real-world applications, even under variable lighting conditions and background noise.
        The <strong>real-time heatmaps</strong> provided clear, interpretable feedback to users, highlighting regions of concern without overwhelming the interface.
        System latency remained consistently low, preserving the feeling of immediate responsiveness that was crucial for real-time applications.
        These results validated both our <strong>model architecture</strong> and our <strong>dataset generation strategy</strong>, confirming the effectiveness of combining <strong>synthetic data</strong> with lightweight <strong>deep learning models</strong> for practical anomaly detection use cases.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/QuizBot_Light.png
      " alt="Description">
    </div>
  </section>

  <section class="project-section left">
    <div class="text">
      <h2>Final Evaluation</h2>
      <p>
        Our final evaluation confirmed that combining <strong>synthetic dataset generation</strong> with a <strong>lightweight deep learning architecture</strong> offers a highly effective approach to real-time anomaly detection.
        The system achieved over <strong>90% precision</strong> across diverse test scenarios, including varying lighting conditions, occlusions, and environmental changes.
        Key lessons included the importance of <strong>diverse and realistic synthetic data</strong>, the benefits of using <strong>SSIM loss</strong> for visual tasks, and the advantages of <strong>compact models</strong> like <strong>EfficientNetB0</strong> for maintaining real-time performance.
        Our results demonstrated that sophisticated anomaly detection does not require complex or heavy architectures when <strong>data quality</strong> and <strong>training methodology</strong> are carefully considered.
        This project highlights the practical potential of applying <strong>machine learning</strong> and <strong>augmented reality</strong> together to build accessible, responsive, and impactful real-world AI systems.
      </p>
    </div>
    <div class="image">
      <img src="/images/projects/AnomalyDetection_Dark.png" alt="Description">
    </div>
  </section>

  <!-- Collaborators Section -->
  <section class="collaborators">
    <h2>Collaborators</h2>
  
    <div class="collaborator" onclick="toggleCollaborator(this)">
      <h3>Syed Ammar Ali</h3>
      <div class="collaborator-links">
        <a href="https://www.linkedin.com/in/ammarswork/" target="_blank">üîó LinkedIn</a>
        <a href="https://github.com/codexammar" target="_blank">üíª GitHub</a>
      </div>
    </div>
  
    <div class="collaborator" onclick="toggleCollaborator(this)">
      <h3>Usba Gohir</h3>
      <div class="collaborator-links">
        <a href="https://www.linkedin.com/in/usbagohir/" target="_blank">üîó LinkedIn</a>
        <a href="#" target="_blank">üíª GitHub</a>
      </div>
    </div>

    <div class="collaborator" onclick="toggleCollaborator(this)">
      <h3>Abdul Aziz Ibrahim</h3>
      <div class="collaborator-links">
        <a href="https://www.linkedin.com/in/abdul-aziz-ibrahim-520385208/" target="_blank">üîó LinkedIn</a>
        <a href="#" target="_blank">üíª GitHub</a>
      </div>
    </div>
  </section>  

  </section>

  <script src="/js/secure-atm-banking-system.js"></script>
</body>
</html>
